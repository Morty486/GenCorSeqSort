All_cor2 <- replicate(1000,Corr_norm(n=1000))
# Display results
summary(All_cor2)
set.seed(123)
library(truncnorm) # Install if needed
install.packages("truncnorm")
set.seed(123)
library(truncnorm) # Install if needed
# Parameters for X and Y
n <- 1000
mu_X <- 0; mu_Y <- 0
sigma_X <- 1; sigma_Y <- 1
rho <- 0.9
# Generate correlated normal variables
library(MASS)
Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
data <- mvrnorm(n, mu = c(mu_X, mu_Y), Sigma = Sigma)
# Truncate the variables
X <- pmin(pmax(data[, 1], -1), 1)
Y <- pmin(pmax(data[, 2], -1), 1)
# Compute correlation
correlation <- cor(X, Y)
cat("Correlation between truncated X and Y (continuous):", correlation, "\n")
set.seed(123)
library(truncnorm) # Install if needed
# Parameters for X and Y
n <- 1000
mu_X <- 0; mu_Y <- 0
sigma_X <- 1; sigma_Y <- 1
rho <- 0.9
# Generate correlated normal variables
library(MASS)
Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
data <- mvrnorm(n, mu = c(mu_X, mu_Y), Sigma = Sigma)
# Truncate the variables
X <- pmin(pmax(data[, 1], -1), 1)
Y <- pmin(pmax(data[, 2], -1), 1)
# Compute correlation
correlation <- cor(X, Y)
cat("Correlation between truncated X and Y (continuous):", correlation, "\n")
set.seed(123) # For reproducibility
# Number of samples
n <- 1000
# Generate uniform random variable V
V <- runif(n, 0, 1)
# Case 1: Maximal Correlation
X_max_corr <- V                 # F^(-1)(V)
Y_max_corr <- V                 # G^(-1)(V)
# Case 2: Maximal Anti-Correlation
X_max_anticorr <- V             # F^(-1)(V)
Y_max_anticorr <- 1 - V         # G^(-1)(1 - V)
# Compute correlations
cor_max_corr <- cor(X_max_corr, Y_max_corr)
cor_max_anticorr <- cor(X_max_anticorr, Y_max_anticorr)
# Print results
cat("Correlation for maximal correlation case:", cor_max_corr, "\n")
cat("Correlation for maximal anti-correlation case:", cor_max_anticorr, "\n")
# Plot the relationships
par(mfrow = c(1, 2)) # Arrange plots in one row, two columns
# Plot maximal correlation
plot(X_max_corr, Y_max_corr, main = "Maximal Correlation",
xlab = "X", ylab = "Y", col = "blue", pch = 16)
# Plot maximal anti-correlation
plot(X_max_anticorr, Y_max_anticorr, main = "Maximal Anti-Correlation",
xlab = "X", ylab = "Y", col = "red", pch = 16)
par(mfrow = c(1, 1)) # Reset plot layout
# 3
set.seed(13)
# Number of samples
n <- 1000
# Generate uniform random variable V
V <- runif(n, 0, 1)
# Case 1: Maximal Correlation
X_max_corr <- V                 # F^(-1)(V)
Y_max_corr <- V                 # G^(-1)(V)
# Case 2: Maximal Anti-Correlation
X_max_anticorr <- V             # F^(-1)(V)
Y_max_anticorr <- 1 - V         # G^(-1)(1 - V)
# Compute correlations
cor_max_corr <- cor(X_max_corr, Y_max_corr)
cor_max_anticorr <- cor(X_max_anticorr, Y_max_anticorr)
# Print results
cat("Correlation for maximal correlation case:", cor_max_corr, "\n")
cat("Correlation for maximal anti-correlation case:", cor_max_anticorr, "\n")
set.seed(13)
# Number of samples
n <- 1000
# Generate uniform random variable V
V <- runif(n, 0, 1)
# Case 1: Maximal Correlation
X_max_corr <- V                 # F^(-1)(V)
Y_max_corr <- V                 # G^(-1)(V)
# Case 2: Maximal Anti-Correlation
X_max_anticorr <- V             # F^(-1)(V)
Y_max_anticorr <- 1 - V         # G^(-1)(1 - V)
# Compute correlations
cor_max_corr <- cor(X_max_corr, Y_max_corr)
cor_max_anticorr <- cor(X_max_anticorr, Y_max_anticorr)
# Print results
cat("Correlation for maximal correlation case:", cor_max_corr, "\n")
cat("Correlation for maximal anti-correlation case:", cor_max_anticorr, "\n")
set.seed(123) # For reproducibility
# Step 1: Generate random samples
N <- 100000 # Large number of observations
X <- runif(N)    # Variable 1: Uniform distribution
Y <- rnorm(N)    # Variable 2: Normal distribution
# Step 2: Lower Bound (Minimal Correlation)
X_sorted_min <- sort(X)                  # Sort X in ascending order
Y_sorted_min <- sort(Y, decreasing = TRUE) # Sort Y in descending order
cor_lower <- cor(X_sorted_min, Y_sorted_min)
# Step 3: Upper Bound (Maximal Correlation)
X_sorted_max <- sort(X) # Sort X in ascending order
Y_sorted_max <- sort(Y) # Sort Y in ascending order
cor_upper <- cor(X_sorted_max, Y_sorted_max)
# Print results
cat("Empirical Lower Bound (Minimal Correlation):", cor_lower, "\n")
cat("Empirical Upper Bound (Maximal Correlation):", cor_upper, "\n")
set.seed(123) # For reproducibility
# Parameters
N <- 100000 # Sample size
replications <- 1000 # Number of replications
theoretical_bound <- sqrt(2 / pi) # Theoretical bound for binary-normal case
# Function to perform a single replication of GSC
run_gsc <- function() {
# Step 1: Generate binary and normal variables
Z <- rnorm(N) # Standard normal variable
B <- as.numeric(Z >= 0) # Dichotomized variable at mean (binary)
# Step 2: Compute lower and upper bounds using sorting
cor_lower <- cor(sort(B), sort(Z, decreasing = TRUE)) # Minimal correlation
cor_upper <- cor(sort(B), sort(Z))                   # Maximal correlation
return(c(cor_lower, cor_upper))
}
# Run GSC algorithm over multiple replications
results <- replicate(replications, run_gsc())
# Compute empirical bounds and confidence intervals
lower_bounds <- results[1, ]
upper_bounds <- results[2, ]
ci_lower <- quantile(lower_bounds, probs = c(0.025, 0.975)) # 95% CI for lower bound
ci_upper <- quantile(upper_bounds, probs = c(0.025, 0.975)) # 95% CI for upper bound
# Output results
cat("Theoretical correlation bound: ±", theoretical_bound, "\n")
cat("Empirical 95% CI for lower bound: ±", ci_lower, "\n")
cat("Empirical 95% CI for upper bound: ±", ci_upper, "\n")
# Function to compute theoretical bounds for binary-binary case
binary_bounds <- function(p1, p2) {
lower_bound <- max(
-sqrt((p1 * p2) / ((1 - p1) * (1 - p2))),
-sqrt(((1 - p1) * (1 - p2)) / (p1 * p2))
)
upper_bound <- min(
sqrt((p1 * (1 - p2)) / ((1 - p1) * p2)),
sqrt(((1 - p1) * p2) / (p1 * (1 - p2)))
)
return(c(Lower_Bound = lower_bound, Upper_Bound = upper_bound))
}
# Example: p1 = 0.5, p2 = 0.6
bounds <- binary_bounds(0.5, 0.6)
print(bounds)
set.seed(123) # For reproducibility
# Parameters
N <- 100000 # Sample size
replications <- 1000 # Number of replications
p1 <- 0.5 # Success probability for variable 1
p2 <- 0.6 # Success probability for variable 2
# Function to run a single GSC replication
run_gsc <- function() {
# Generate binary variables
X <- rbinom(N, 1, p1) # Binary variable 1
Y <- rbinom(N, 1, p2) # Binary variable 2
# Lower bound: Sort X and Y in opposite directions
cor_lower <- cor(sort(X), sort(Y, decreasing = TRUE))
# Upper bound: Sort X and Y in the same direction
cor_upper <- cor(sort(X), sort(Y))
return(c(cor_lower, cor_upper))
}
# Run GSC over multiple replications
results <- replicate(replications, run_gsc())
# Extract bounds
lower_bounds <- results[1, ]
upper_bounds <- results[2, ]
# Compute mean bounds and 95% confidence intervals
mean_lower <- mean(lower_bounds)
mean_upper <- mean(upper_bounds)
ci_lower <- quantile(lower_bounds, probs = c(0.025, 0.975))
ci_upper <- quantile(upper_bounds, probs = c(0.025, 0.975))
# Print results
cat("Empirical Upper Limit:", mean_upper, "with CI", ci_upper, "\n")
cat("Empirical Lower Limit:", mean_lower, "with CI", ci_lower, "\n")
set.seed(12) # For reproducibility
# Parameters
N <- 10000 # Sample size
replications <- 1000 # Number of replications
p1 <- 0.5 # Success probability for variable 1
p2 <- 0.6 # Success probability for variable 2
# Function to run a single GSC replication
run_gsc <- function() {
# Generate binary variables
X <- rbinom(N, 1, p1) # Binary variable 1
Y <- rbinom(N, 1, p2) # Binary variable 2
# Lower bound: Sort X and Y in opposite directions
cor_lower <- cor(sort(X), sort(Y, decreasing = TRUE))
# Upper bound: Sort X and Y in the same direction
cor_upper <- cor(sort(X), sort(Y))
return(c(cor_lower, cor_upper))
}
# Run GSC over multiple replications
results <- replicate(replications, run_gsc())
# Extract bounds
lower_bounds <- results[1, ]
upper_bounds <- results[2, ]
# Compute mean bounds and 95% confidence intervals
mean_lower <- mean(lower_bounds)
mean_upper <- mean(upper_bounds)
ci_lower <- quantile(lower_bounds, probs = c(0.025, 0.975))
ci_upper <- quantile(upper_bounds, probs = c(0.025, 0.975))
# Print results
cat("Empirical Upper Limit:", mean_upper, "with CI", ci_upper, "\n")
cat("Empirical Lower Limit:", mean_lower, "with CI", ci_lower, "\n")
set.seed(123) # For reproducibility
# Parameters
sigma1_sq <- 0.5 # Variance of Y1
sigma2_sq <- 0.5 # Variance of Y2
rho_y <- -1      # Correlation between Y1 and Y2 (for lower bound)
N <- 100000      # Number of samples
# Generate jointly normal variables
library(MASS)
mu <- c(0, 0) # Means
Sigma <- matrix(c(sigma1_sq, rho_y * sqrt(sigma1_sq * sigma2_sq),
rho_y * sqrt(sigma1_sq * sigma2_sq), sigma2_sq), 2, 2)
Y <- mvrnorm(N, mu, Sigma)
# Transform to log-normal
X1 <- exp(Y[, 1])
X2 <- exp(Y[, 2])
# Compute correlation (empirical lower bound)
cor_lower <- cor(sort(X1), sort(X2, decreasing = TRUE))
cat("Empirical lower bound for delta_x:", cor_lower, "\n")
set.seed(123) # For reproducibility
# Parameters
N <- 100000 # Sample size
replications <- 1000 # Number of replications
sigma1_sq <- 0.5 # Variance of Y1
sigma2_sq <- 0.5 # Variance of Y2
# Function to generate log-normal variables and compute bounds
run_gsc <- function(sigma1_sq, sigma2_sq, rho_y) {
library(MASS)
# Generate jointly normal variables
mu <- c(0, 0) # Means
Sigma <- matrix(c(sigma1_sq, rho_y * sqrt(sigma1_sq * sigma2_sq),
rho_y * sqrt(sigma1_sq * sigma2_sq), sigma2_sq), 2, 2)
Y <- mvrnorm(N, mu, Sigma)
# Transform to log-normal
X1 <- exp(Y[, 1])
X2 <- exp(Y[, 2])
# Lower bound: Sort X1 ascending, X2 descending
cor_lower <- cor(sort(X1), sort(X2, decreasing = TRUE))
# Upper bound: Sort both X1 and X2 ascending
cor_upper <- cor(sort(X1), sort(X2))
return(c(cor_lower, cor_upper))
}
# Run GSC for multiple replications
results <- replicate(replications, run_gsc(sigma1_sq, sigma2_sq, rho_y = -1))
# Extract bounds
lower_bounds <- results[1, ]
upper_bounds <- results[2, ]
# Compute mean bounds and 95% confidence intervals
mean_lower <- mean(lower_bounds)
mean_upper <- mean(upper_bounds)
ci_lower <- quantile(lower_bounds, probs = c(0.025, 0.975))
ci_upper <- quantile(upper_bounds, probs = c(0.025, 0.975))
# Output results
cat("Empirical Lower Bound for delta_x:", mean_lower, "with CI", ci_lower, "\n")
cat("Empirical Upper Bound for delta_x:", mean_upper, "with CI", ci_upper, "\n")
set.seed(123) # For reproducibility
# Number of samples
N <- 100000
# Generate samples for each variable
X1 <- rbinom(N, 1, 0.8) # Binary (Bernoulli)
X2 <- rpois(N, 1)       # Poisson
X3 <- sample(1:4, N, replace = TRUE, prob = c(0.1, 0.4, 0.1, 0.4)) # Ordinal
pi <- 0.2
X4 <- ifelse(runif(N) < pi, rnorm(N, 0, sqrt(3)), rnorm(N, 4, sqrt(8))) # Normal Mixture
lambda_params <- c(0, 1, 1, 10) # Generalized Lambda parameters
p <- runif(N)
X5 <- lambda_params[1] + (p^lambda_params[3] - (1 - p)^lambda_params[4]) / lambda_params[2] # Lambda distribution
# Function to compute correlation bounds
compute_bounds <- function(X, Y) {
cor_lower <- cor(sort(X), sort(Y, decreasing = TRUE)) # Lower bound
cor_upper <- cor(sort(X), sort(Y))                   # Upper bound
return(c(Lower = cor_lower, Upper = cor_upper))
}
# Initialize results
variables <- list(X1, X2, X3, X4, X5)
n <- length(variables)
lower_bounds <- matrix(NA, n, n)
upper_bounds <- matrix(NA, n, n)
# Compute bounds for all pairs
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
bounds <- compute_bounds(variables[[i]], variables[[j]])
lower_bounds[j, i] <- bounds["Lower"] # Fill lower triangle
upper_bounds[i, j] <- bounds["Upper"] # Fill upper triangle
}
}
# Combine into a single matrix for display
bounds_matrix <- lower_bounds + t(upper_bounds)
rownames(bounds_matrix) <- colnames(bounds_matrix) <- paste0("X", 1:5)
# Display results
bounds_matrix
set.seed(123) # For reproducibility
# Number of samples
N <- 100000
# Generate samples for each variable
X1 <- rbinom(N, 1, 0.8) # Binary (Bernoulli)
X2 <- rpois(N, 1)       # Poisson
X3 <- sample(1:4, N, replace = TRUE, prob = c(0.1, 0.4, 0.1, 0.4)) # Ordinal
pi <- 0.2
X4 <- ifelse(runif(N) < pi, rnorm(N, 0, sqrt(3)), rnorm(N, 4, sqrt(8))) # Normal Mixture
lambda_params <- c(0, 1, 1, 10) # Generalized Lambda parameters
p <- runif(N)
X5 <- lambda_params[1] + (p^lambda_params[3] - (1 - p)^lambda_params[4]) / lambda_params[2] # Lambda distribution
# Function to compute correlation bounds
compute_bounds <- function(X, Y) {
cor_lower <- cor(sort(X), sort(Y, decreasing = TRUE)) # Lower bound
cor_upper <- cor(sort(X), sort(Y))                   # Upper bound
return(c(Lower = cor_lower, Upper = cor_upper))
}
# Initialize results
variables <- list(X1, X2, X3, X4, X5)
n <- length(variables)
lower_bounds <- matrix(NA, n, n)
upper_bounds <- matrix(NA, n, n)
# Compute bounds for all pairs
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
bounds <- compute_bounds(variables[[i]], variables[[j]])
lower_bounds[j, i] <- bounds["Lower"] # Fill lower triangle
upper_bounds[i, j] <- bounds["Upper"] # Fill upper triangle
}
}
# Combine into a single matrix for display
bounds_matrix <- lower_bounds + t(upper_bounds)
rownames(bounds_matrix) <- colnames(bounds_matrix) <- paste0("X", 1:5)
# Display results
print(bounds_matrix)
head(X1)
head(X2)
head(X3)
head(X3,20)
head(X5,20)
summary(X1)
summary(X2)
summary(X3)
summary(X4)
summary(X5)
lower_bounds
upper_bound
upper_bounds
# Combine into a single matrix for display
bounds_matrix <- lower_bounds + upper_bounds
rownames(bounds_matrix) <- colnames(bounds_matrix) <- paste0("X", 1:5)
# Display results
print(bounds_matrix)
# Combine lower and upper bounds into a single matrix
bounds_matrix <- matrix(NA, nrow = n, ncol = n)
# Fill lower triangle with lower bounds and upper triangle with upper bounds
bounds_matrix[lower.tri(bounds_matrix)] <- lower_bounds[lower.tri(lower_bounds)]
bounds_matrix[upper.tri(bounds_matrix)] <- upper_bounds[upper.tri(upper_bounds)]
# Set row and column names
rownames(bounds_matrix) <- colnames(bounds_matrix) <- paste0("X", 1:5)
# Display the results
print(bounds_matrix)
# Combine lower and upper bounds into a single matrix
bounds_matrix <- matrix(NA, nrow = n, ncol = n)
# Fill lower triangle with lower bounds and upper triangle with upper bounds
bounds_matrix[lower.tri(bounds_matrix)] <- lower_bounds[lower.tri(lower_bounds)]
bounds_matrix[upper.tri(bounds_matrix)] <- upper_bounds[upper.tri(upper_bounds)]
# Set row and column names
rownames(bounds_matrix) <- colnames(bounds_matrix) <- paste0("X", 1:5)
# Display the results
print(bounds_matrix)
set.seed(123) # For reproducibility
# Number of samples
N <- 100000
# Generate samples for each variable
X1 <- rbinom(N, 1, 0.8) # Binary (Bernoulli)
X2 <- rpois(N, 1)       # Poisson
X3 <- sample(1:4, N, replace = TRUE, prob = c(0.1, 0.4, 0.1, 0.4)) # Ordinal
pi <- 0.2
X4 <- ifelse(runif(N) < pi, rnorm(N, 0, sqrt(3)), rnorm(N, 4, sqrt(8))) # Normal Mixture
lambda_params <- c(0, 1, 1, 10) # Generalized Lambda parameters
p <- runif(N)
X5 <- lambda_params[1] +
(p^lambda_params[3] - (1 - p)^lambda_params[4]) / lambda_params[2]
# Lambda distribution
# Function to compute correlation bounds
compute_bounds <- function(X, Y) {
cor_lower <- cor(sort(X), sort(Y, decreasing = TRUE)) # Lower bound
cor_upper <- cor(sort(X), sort(Y))                   # Upper bound
return(c(Lower = cor_lower, Upper = cor_upper))
}
# Initialize results
variables <- list(X1, X2, X3, X4, X5)
n <- length(variables)
lower_bounds <- matrix(NA, n, n)
upper_bounds <- matrix(NA, n, n)
# Compute bounds for all pairs
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
bounds <- compute_bounds(variables[[i]], variables[[j]])
lower_bounds[j, i] <- bounds["Lower"] # Fill lower triangle
upper_bounds[i, j] <- bounds["Upper"] # Fill upper triangle
}
}
# Combine lower and upper bounds into a single matrix
bounds_matrix <- matrix(NA, nrow = n, ncol = n)
# Fill lower triangle with lower bounds and upper triangle with upper bounds
bounds_matrix[lower.tri(bounds_matrix)] <- lower_bounds[lower.tri(lower_bounds)]
bounds_matrix[upper.tri(bounds_matrix)] <- upper_bounds[upper.tri(upper_bounds)]
# Set row and column names
rownames(bounds_matrix) <- colnames(bounds_matrix) <- paste0("X", 1:5)
# Display the results
print(bounds_matrix)
set.seed(123) # For reproducibility
# Number of samples
N <- 100000
# Generate samples for each variable
X1 <- rbinom(N, 1, 0.8) # Binary (Bernoulli)
X2 <- rpois(N, 1)       # Poisson
X3 <- sample(1:4, N, replace = TRUE, prob = c(0.1, 0.4, 0.1, 0.4)) # Ordinal
X4 <- ifelse(runif(N) < pi, rnorm(N, 0, sqrt(3)), rnorm(N, 4, sqrt(8)))
lambda_params <- c(0, 1, 1, 10) # Generalized Lambda parameters
p <- runif(N)
X5 <- lambda_params[1] +
(p^lambda_params[3] - (1 - p)^lambda_params[4]) / lambda_params[2]
# Lambda distribution
# Function to compute correlation bounds
compute_bounds <- function(X, Y) {
cor_lower <- cor(sort(X), sort(Y, decreasing = TRUE)) # Lower bound
cor_upper <- cor(sort(X), sort(Y))                   # Upper bound
return(c(Lower = cor_lower, Upper = cor_upper))
}
# Initialize results
variables <- list(X1, X2, X3, X4, X5)
n <- length(variables)
lower_bounds <- matrix(NA, n, n)
upper_bounds <- matrix(NA, n, n)
# Compute bounds for all pairs
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
bounds <- compute_bounds(variables[[i]], variables[[j]])
lower_bounds[j, i] <- bounds["Lower"] # Fill lower triangle
upper_bounds[i, j] <- bounds["Upper"] # Fill upper triangle
}
}
# Combine lower and upper bounds into a single matrix
bounds_matrix <- matrix(NA, nrow = n, ncol = n)
# Fill lower triangle with lower bounds and upper triangle with upper bounds
bounds_matrix[lower.tri(bounds_matrix)] <- lower_bounds[lower.tri(lower_bounds)]
bounds_matrix[upper.tri(bounds_matrix)] <- upper_bounds[upper.tri(upper_bounds)]
# Set row and column names
rownames(bounds_matrix) <- colnames(bounds_matrix) <- paste0("X", 1:5)
# Display the results
print(bounds_matrix)
set.seed(123) # For reproducibility
# Number of samples
N <- 100000
# Generate samples for each variable
X1 <- rbinom(N, 1, 0.8) # Binary (Bernoulli)
X2 <- rpois(N, 1)       # Poisson
X3 <- sample(1:4, N, replace = TRUE, prob = c(0.1, 0.4, 0.1, 0.4)) # Ordinal
# Parameters for the mixture distribution
pi <- 0.2 # Mixture probability
mu1 <- 0; sigma1_sq <- 3 # Parameters for first normal distribution
mu2 <- 4; sigma2_sq <- 8 # Parameters for second normal distribution
# Simulate the mixture
indicator <- rbinom(N, 1, pi) # Bernoulli indicator (1 = N(mu1, sigma1_sq), 0 = N(mu2, sigma2_sq))
X4 <- indicator * rnorm(N, mu1, sqrt(sigma1_sq)) + (1 - indicator) * rnorm(N, mu2, sqrt(sigma2_sq))
lambda_params <- c(0, 1, 1, 10) # Generalized Lambda parameters
p <- runif(N)
X5 <- lambda_params[1] +
(p^lambda_params[3] - (1 - p)^lambda_params[4]) / lambda_params[2]
# Lambda distribution
# Function to compute correlation bounds
compute_bounds <- function(X, Y) {
cor_lower <- cor(sort(X), sort(Y, decreasing = TRUE)) # Lower bound
cor_upper <- cor(sort(X), sort(Y))                   # Upper bound
return(c(Lower = cor_lower, Upper = cor_upper))
}
# Initialize results
variables <- list(X1, X2, X3, X4, X5)
n <- length(variables)
lower_bounds <- matrix(NA, n, n)
upper_bounds <- matrix(NA, n, n)
# Compute bounds for all pairs
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
bounds <- compute_bounds(variables[[i]], variables[[j]])
lower_bounds[j, i] <- bounds["Lower"] # Fill lower triangle
upper_bounds[i, j] <- bounds["Upper"] # Fill upper triangle
}
}
# Combine lower and upper bounds into a single matrix
bounds_matrix <- matrix(NA, nrow = n, ncol = n)
# Fill lower triangle with lower bounds and upper triangle with upper bounds
bounds_matrix[lower.tri(bounds_matrix)] <- lower_bounds[lower.tri(lower_bounds)]
bounds_matrix[upper.tri(bounds_matrix)] <- upper_bounds[upper.tri(upper_bounds)]
# Set row and column names
rownames(bounds_matrix) <- colnames(bounds_matrix) <- paste0("X", 1:5)
# Display the results
print(bounds_matrix)
0.8/0.9094
install.packages("GenCorSeqSort")
